{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# School and Hospital external dataset\n",
    "# This notebook aims to webscrapying the hospital and school data for every suburb based on the SA2_code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API_keys:AIzaSyCN_HvPAmTVnCRkeJybUm7wee9YvTYWCcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Google Maps API\n",
    "API_KEY = 'AIzaSyCmU1epyXmI4mawecIz1qU7he_0VBQJDwo'  \n",
    "\n",
    "places_url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "\n",
    "# API daily call limit\n",
    "MAX_DAILY_CALLS = 6000  \n",
    "CALLS_MADE = 0  \n",
    "\n",
    "# Latitude and longitude range of Victoria\n",
    "VIC_LAT_MIN = -39.159  \n",
    "VIC_LAT_MAX = -33.981  \n",
    "VIC_LNG_MIN = 140.961  \n",
    "VIC_LNG_MAX = 149.976  \n",
    "\n",
    "# Gridding Victoria's regions\n",
    "GRID_STEP = 0.05  \n",
    "# Save processed grid files\n",
    "processed_locations_file = 'processed_locations.txt'\n",
    "\n",
    "# Read the processed grid\n",
    "if os.path.exists(processed_locations_file):\n",
    "    with open(processed_locations_file, 'r') as file:\n",
    "        processed_locations = set(file.read().splitlines())\n",
    "else:\n",
    "    processed_locations = set()\n",
    "\n",
    "# Functions to search for hospitals and schools\n",
    "def get_places_data(keyword, location, radius=5000):\n",
    "    global CALLS_MADE\n",
    "    if CALLS_MADE >= MAX_DAILY_CALLS:\n",
    "        print(\"Reach the daily API call limit and suspend the operation.\")\n",
    "        return None\n",
    "\n",
    "    params = {\n",
    "        'location': location,  \n",
    "        'radius': radius,  \n",
    "        'type': keyword,  \n",
    "        'key': API_KEY\n",
    "    }\n",
    "\n",
    "    response = requests.get(places_url, params=params)\n",
    "    CALLS_MADE += 1  \n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json().get('results', [])\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Convert results to DataFrame\n",
    "def places_to_dataframe(places_data):\n",
    "    if not places_data:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    places_list = []\n",
    "    for place in places_data:\n",
    "        place_info = {\n",
    "            'name': place['name'],\n",
    "            'address': place.get('vicinity'),\n",
    "            'lat': place['geometry']['location']['lat'],\n",
    "            'lng': place['geometry']['location']['lng'],\n",
    "            'place_id': place['place_id']\n",
    "        }\n",
    "        places_list.append(place_info)\n",
    "    \n",
    "    return pd.DataFrame(places_list)\n",
    "\n",
    "# Generate a Victorian-wide latitude/longitude grid\n",
    "def generate_grid():\n",
    "    latitudes = [VIC_LAT_MIN + i * GRID_STEP for i in range(int((VIC_LAT_MAX - VIC_LAT_MIN) / GRID_STEP) + 1)]\n",
    "    longitudes = [VIC_LNG_MIN + i * GRID_STEP for i in range(int((VIC_LNG_MAX - VIC_LNG_MIN) / GRID_STEP) + 1)]\n",
    "    \n",
    "    grid = []\n",
    "    for lat in latitudes:\n",
    "        for lng in longitudes:\n",
    "            grid.append(f\"{lat},{lng}\")\n",
    "    \n",
    "    return grid\n",
    "\n",
    "# Batch fetch data and control the number of calls per day\n",
    "def fetch_places_for_victoria(grid_locations):\n",
    "    all_places = []\n",
    "\n",
    "    for location in grid_locations:\n",
    "        if location in processed_locations:\n",
    "            continue  # Skip processed grids\n",
    "\n",
    "        if CALLS_MADE >= MAX_DAILY_CALLS:\n",
    "            print(f\"Maximum number of calls per day {MAX_DAILY_CALLS} has been reached, continue crawling data tomorrow.\")\n",
    "            break\n",
    "\n",
    "        # Access to hospital data\n",
    "        hospitals = get_places_data('hospital', location)\n",
    "        if hospitals:\n",
    "            all_places.extend(hospitals)\n",
    "        \n",
    "        # Access to school data\n",
    "        schools = get_places_data('school', location)\n",
    "        if schools:\n",
    "            all_places.extend(schools)\n",
    "\n",
    "        # Mark the grid as processed\n",
    "        processed_locations.add(location)\n",
    "\n",
    "        # Control the frequency of requests to prevent being flow-limited\n",
    "        time.sleep(2) \n",
    "\n",
    "    # Save processed grids\n",
    "    with open(processed_locations_file, 'w') as file:\n",
    "        file.write('\\n'.join(processed_locations))\n",
    "\n",
    "    return places_to_dataframe(all_places)\n",
    "\n",
    "# Generate grid latitude and longitude for Victoria\n",
    "grid_locations = generate_grid()\n",
    "\n",
    "df_all_places = fetch_places_for_victoria(grid_locations)\n",
    "\n",
    "output_folder = '../data/landing/External_data/school_hospital_data'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_folder, 'hospitals_and_schools_victoria.csv')\n",
    "df_all_places.to_csv(output_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "vscode": {
   "interpreter": {
    "hash": "4da9767ede2aa5dda80421e17bc7538037e137690e850a94458f7447dae52089"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
