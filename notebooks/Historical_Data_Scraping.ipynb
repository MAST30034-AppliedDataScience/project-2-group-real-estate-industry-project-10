{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# 目标URL\n",
    "url = \"https://www.matthewproctor.com/full_australian_postcodes_vic\"\n",
    "\n",
    "# 获取网页内容\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# 找到表格\n",
    "table = soup.find('table')\n",
    "\n",
    "# 提取表格中的数据并存入列表，跳过标题行\n",
    "data = []\n",
    "rows = table.find_all('tr')[1:]  # 跳过表格的第一行标题\n",
    "for row in rows:\n",
    "    columns = row.find_all('td')\n",
    "    if len(columns) > 2:  # 确保列数足够\n",
    "        Postcode = columns[1].text.strip()  # 第二列是邮政编码\n",
    "        Locality = columns[2].text.strip()  # 第三列是地区\n",
    "        data.append([Locality, Postcode])\n",
    "\n",
    "# 输出结果\n",
    "postcode_locality_list = data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/MELBOURNE/3000/rent/1\n",
      "Page not found: https://www.oldlistings.com.au/real-estate/VIC/MELBOURNE/3000/rent/1\n",
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/MELBOURNE/3001/rent/1\n",
      "Page not found: https://www.oldlistings.com.au/real-estate/VIC/MELBOURNE/3001/rent/1\n",
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/EAST+MELBOURNE/3002/rent/1\n",
      "Page not found: https://www.oldlistings.com.au/real-estate/VIC/EAST+MELBOURNE/3002/rent/1\n",
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/WEST+MELBOURNE/3003/rent/1\n",
      "Page not found: https://www.oldlistings.com.au/real-estate/VIC/WEST+MELBOURNE/3003/rent/1\n",
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/MELBOURNE/3004/rent/1\n",
      "Page not found: https://www.oldlistings.com.au/real-estate/VIC/MELBOURNE/3004/rent/1\n",
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/ST+KILDA+ROAD+CENTRAL/3004/rent/1\n",
      "Page not found: https://www.oldlistings.com.au/real-estate/VIC/ST+KILDA+ROAD+CENTRAL/3004/rent/1\n",
      "Checking first page: https://www.oldlistings.com.au/real-estate/VIC/ST+KILDA+ROAD+MELBOURNE/3004/rent/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ryanwang/Documents/GitHub/MAST30034_Python/project-2-group-real-estate-industry-project-10/notebooks/Historical_Data_Scraping.ipynb Cell 2\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryanwang/Documents/GitHub/MAST30034_Python/project-2-group-real-estate-industry-project-10/notebooks/Historical_Data_Scraping.ipynb#W1sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mChecking first page: \u001b[39m\u001b[39m{\u001b[39;00murl\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryanwang/Documents/GitHub/MAST30034_Python/project-2-group-real-estate-industry-project-10/notebooks/Historical_Data_Scraping.ipynb#W1sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39m# Send request to get the first page content\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ryanwang/Documents/GitHub/MAST30034_Python/project-2-group-real-estate-industry-project-10/notebooks/Historical_Data_Scraping.ipynb#W1sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39;49mget(url, headers\u001b[39m=\u001b[39;49mheaders)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryanwang/Documents/GitHub/MAST30034_Python/project-2-group-real-estate-industry-project-10/notebooks/Historical_Data_Scraping.ipynb#W1sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m# Check response status\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ryanwang/Documents/GitHub/MAST30034_Python/project-2-group-real-estate-industry-project-10/notebooks/Historical_Data_Scraping.ipynb#W1sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m==\u001b[39m \u001b[39m200\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:75\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(url, params\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     65\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \n\u001b[1;32m     67\u001b[0m \u001b[39m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mreturn\u001b[39;00m request(\u001b[39m'\u001b[39;49m\u001b[39mget\u001b[39;49m\u001b[39m'\u001b[39;49m, url, params\u001b[39m=\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/api.py:61\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39mwith\u001b[39;00m sessions\u001b[39m.\u001b[39mSession() \u001b[39mas\u001b[39;00m session:\n\u001b[0;32m---> 61\u001b[0m     \u001b[39mreturn\u001b[39;00m session\u001b[39m.\u001b[39;49mrequest(method\u001b[39m=\u001b[39;49mmethod, url\u001b[39m=\u001b[39;49murl, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:529\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    524\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    525\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m'\u001b[39m: timeout,\n\u001b[1;32m    526\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m'\u001b[39m: allow_redirects,\n\u001b[1;32m    527\u001b[0m }\n\u001b[1;32m    528\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 529\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    531\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/sessions.py:645\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    642\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    644\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 645\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    647\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    648\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/adapters.py:440\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    439\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 440\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    441\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    442\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    443\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    444\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    445\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    446\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    447\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    448\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    449\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    450\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout\n\u001b[1;32m    451\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    454\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m'\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    704\u001b[0m     conn,\n\u001b[1;32m    705\u001b[0m     method,\n\u001b[1;32m    706\u001b[0m     url,\n\u001b[1;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    711\u001b[0m )\n\u001b[1;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    717\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:386\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_conn(conn)\n\u001b[1;32m    387\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    388\u001b[0m     \u001b[39m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mconn\u001b[39m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py:1040\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1038\u001b[0m \u001b[39m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mgetattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39msock\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):  \u001b[39m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1040\u001b[0m     conn\u001b[39m.\u001b[39;49mconnect()\n\u001b[1;32m   1042\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m conn\u001b[39m.\u001b[39mis_verified:\n\u001b[1;32m   1043\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1044\u001b[0m         (\n\u001b[1;32m   1045\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnverified HTTPS request is being made to host \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1051\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:358\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    357\u001b[0m     \u001b[39m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 358\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m conn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_new_conn()\n\u001b[1;32m    359\u001b[0m     hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost\n\u001b[1;32m    360\u001b[0m     tls_in_tls \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    171\u001b[0m     extra_kw[\u001b[39m\"\u001b[39m\u001b[39msocket_options\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msocket_options\n\u001b[1;32m    173\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dns_host, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mport), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[39mexcept\u001b[39;00m SocketTimeout:\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConnection to \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m timed out. (connect timeout=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[39mif\u001b[39;00m source_address:\n\u001b[1;32m     84\u001b[0m         sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m     sock\u001b[39m.\u001b[39;49mconnect(sa)\n\u001b[1;32m     86\u001b[0m     \u001b[39mreturn\u001b[39;00m sock\n\u001b[1;32m     88\u001b[0m \u001b[39mexcept\u001b[39;00m socket\u001b[39m.\u001b[39merror \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# Base URL\n",
    "base_url = 'https://www.oldlistings.com.au/real-estate/VIC'\n",
    "\n",
    "# Fake headers to simulate a browser visit\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36',\n",
    "    'Referer': 'https://www.oldlistings.com.au',\n",
    "    'Accept-Language': 'en-US,en;q=0.9'\n",
    "}\n",
    "\n",
    "# List of Victoria cities and postcodes\n",
    "victoria_cities_postcodes = postcode_locality_list  # Assuming postcode_data is the nested list constructed earlier\n",
    "\n",
    "# Open CSV file to save the extracted data\n",
    "with open('../data/landing/historical_data.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write headers for CSV\n",
    "    writer.writerow(['Address', 'Latitude', 'Longitude', 'Bedrooms', 'Bathrooms', 'Property Type', 'Last Advertised Price', 'Price History'])\n",
    "\n",
    "    # Loop through each city and postcode, generate URL and try scraping\n",
    "    for city, postcode in victoria_cities_postcodes:\n",
    "        # Replace spaces in city names with plus signs for the URL\n",
    "        city_url = city.replace(' ', '+')\n",
    "\n",
    "        # First, check the first page to see if there is any valid data\n",
    "        url = f'{base_url}/{city_url}/{postcode}/rent/1'\n",
    "        print(f'Checking first page: {url}')\n",
    "        \n",
    "        # Send request to get the first page content\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        # Check response status\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            # Assuming there is property information on the page, extract address, price, etc.\n",
    "            property_div = soup.find('div', class_='property')\n",
    "\n",
    "            # If the first page doesn't contain any data, skip the current postcode\n",
    "            if not property_div:\n",
    "                print(f'No valid property information, skipping postcode: {postcode}')\n",
    "                continue  # Skip current postcode and move to the next one\n",
    "\n",
    "        else:\n",
    "            print(f'Page not found: {url}')\n",
    "            continue  # If the first page cannot be accessed, skip this postcode\n",
    "\n",
    "        # If there is data on the first page, continue scraping other pages for the postcode\n",
    "        for listing_id in range(1, 1001):\n",
    "            url = f'{base_url}/{city_url}/{postcode}/rent/{listing_id}'\n",
    "            print(f'Scraping: {url}')\n",
    "            \n",
    "            # Send request to get page content\n",
    "            response = requests.get(url, headers=headers)\n",
    "            \n",
    "            # Check response status code\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                \n",
    "                # Assuming there is property information on the page, extract address, price, etc.\n",
    "                property_div = soup.find('div', class_='property')\n",
    "                \n",
    "                if not property_div:\n",
    "                    print(f'No valid property information, skipping: {url}')\n",
    "                    continue  # If no data is found on the current page, skip this page\n",
    "\n",
    "                # Extract latitude and longitude information\n",
    "                latitude = property_div.get('data-lat', 'No latitude info')\n",
    "                longitude = property_div.get('data-lng', 'No longitude info')\n",
    "                \n",
    "                # Extract address\n",
    "                address = property_div.find('h2', class_='address').text.strip() if property_div.find('h2', class_='address') else 'No address'\n",
    "\n",
    "                # Extract number of bedrooms\n",
    "                bedrooms = property_div.find('p', class_='property-meta bed').text.strip() if property_div.find('p', class_='property-meta bed') else 'No bedroom info'\n",
    "\n",
    "                # Extract number of bathrooms\n",
    "                bathrooms = property_div.find('p', class_='property-meta bath').text.strip() if property_div.find('p', class_='property-meta bath') else 'No bathroom info'\n",
    "\n",
    "                # Extract property type\n",
    "                property_type = property_div.find('p', class_='property-meta type').text.strip() if property_div.find('p', class_='property-meta type') else 'No type info'\n",
    "\n",
    "                # Extract last advertised price\n",
    "                last_price = property_div.find('section', class_='price').find('h3').text.strip() if property_div.find('section', class_='price') else 'No price info'\n",
    "\n",
    "                # Extract historical price information\n",
    "                historical_prices_section = property_div.find('section', class_='historical-price')\n",
    "                historical_prices = historical_prices_section.find_all('li') if historical_prices_section else []\n",
    "\n",
    "                # Iterate through historical prices\n",
    "                price_history = []\n",
    "                for price in historical_prices:\n",
    "                    date = price.find('span').text.strip()\n",
    "                    amount = price.contents[1].strip()  # The price is usually the text after the span\n",
    "                    price_history.append(f\"{date}: {amount}\")\n",
    "                \n",
    "                # Write data to CSV\n",
    "                writer.writerow([address, latitude, longitude, bedrooms, bathrooms, property_type, last_price, '; '.join(price_history)])\n",
    "\n",
    "                # Print property information (optional)\n",
    "                print(f'Address: {address}')\n",
    "                print(f'Latitude: {latitude}, Longitude: {longitude}')\n",
    "                print(f'Bedrooms: {bedrooms}')\n",
    "                print(f'Bathrooms: {bathrooms}')\n",
    "                print(f'Property Type: {property_type}')\n",
    "                print(f'Last Advertised Price: {last_price}')\n",
    "                print(\"Price History:\")\n",
    "                for history in price_history:\n",
    "                    print(history)\n",
    "                print('-' * 40)\n",
    "\n",
    "            else:\n",
    "                print(f'Page not found: {url}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (4.5.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: trio~=0.17 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: sortedcontainers in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: idna in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/ryanwang/opt/anaconda3/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4da9767ede2aa5dda80421e17bc7538037e137690e850a94458f7447dae52089"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
